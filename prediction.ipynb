{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTENC, SMOTE\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from scipy import stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet, RidgeClassifierCV, RidgeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_exploration(df):\n",
    "    print(df.describe())\n",
    "    print(df.info())\n",
    "    for col in df.columns:\n",
    "        if col not in ['id','label']:\n",
    "            sns.histplot(df[col])\n",
    "            plt.show()\n",
    "    sns.heatmap(df.corr())\n",
    "    plt.show()\n",
    "    print('*'*50,'\\n','Label correlation')\n",
    "    print(df.corr().iloc[:,-1])\n",
    "    print('*'*50, '\\n', 'Highly correlated columns')\n",
    "\n",
    "    \n",
    "    temp = df.corr().abs()\n",
    "    for col in temp.columns:\n",
    "        temp2 = temp[col].values.tolist()\n",
    "        temp3 = [i for i in temp2 if (i > 0.7) and (i < 1)]\n",
    "        if temp3:\n",
    "            print(col, temp3)\n",
    "            print(df.corr()[col])\n",
    "    print('*'*50)\n",
    "    print(df.corr().iloc[:,-1:])\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(df,  mode , hybrid, drop_cols=None, dropna=False, drop_outlier=0, normalize=None, fr=0, upsampling=False, aggregate=False):\n",
    "    print('*'*50)\n",
    "    print('Mode:', mode)\n",
    "    \n",
    "    if dropna:\n",
    "        df =df.dropna().reset_index(drop=True)\n",
    "        print('Dropped NA value')\n",
    "        \n",
    "    if mode == 'train':\n",
    "        label = df['label'].copy()\n",
    "        df = df.drop('label', axis=1)\n",
    "        print('saved label', len(label))\n",
    "        \n",
    "#     df = df.drop('id', axis=1)\n",
    "#     df = df.drop('Age', axis=1)\n",
    "#     df = df.drop('Sex 0M1F', axis=1)\n",
    "\n",
    "    if drop_cols is not None:\n",
    "        print('Dropped cols', drop_cols)\n",
    "        df = df.drop(drop_cols, axis=1)\n",
    "        \n",
    "#     df['sum'] = df.apply(lambda x : sum(x), axis=1)\n",
    "#     df['pos_sum'] = df['Mono CD64+MFI (cells/ul)'] + df['Neu CD64+MFI (cells/ul)']\n",
    "#     df['neg_sum'] = df['MO HLADR+ MFI (cells/ul)'] + df['CD3+T (cells/ul)']+df['CD8+T (cells/ul)']+df['CD4+T (cells/ul)']+df['CD19+ (cells/ul)']+ df['CD45+ (cells/ul)']\n",
    "    if aggregate:\n",
    "        df['aggregate'] = df['CD3+T (cells/ul)'] + df[ 'CD45+ (cells/ul)']\n",
    "        df = df.drop(['CD3+T (cells/ul)','CD45+ (cells/ul)'], axis = 1)\n",
    "#         df['aggregate2'] = df['NK (cells/ul)'] + df['CD19+ (cells/ul)'] +  df['aggregate']\n",
    "#         df = df.drop(['CD19+ (cells/ul)'], axis = 1)\n",
    "    \n",
    "    if drop_outlier:\n",
    "        print('Before trim outlier, df shape:',df.shape)\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "        df = df[(np.abs(stats.zscore(df)) < drop_outlier).all(axis=1)]\n",
    "        print('After trim outlier, df shape:',df.shape)\n",
    "\n",
    "    if normalize is not None:\n",
    "        if normalize == 'log':\n",
    "            for col in df.columns:\n",
    "                df[col] = np.log10(df[col]+1)\n",
    "            print('Normalized with log10.')\n",
    "        elif normalize == 'minmax':\n",
    "            scaler = MinMaxScaler(feature_range=(0,fr))\n",
    "            df.iloc[:, :] = scaler.fit_transform(df.iloc[:, :])\n",
    "            print('Normalized with minmax.')\n",
    "        elif normalize == 'log_nat':\n",
    "            for col in df.columns:\n",
    "                df[col] = np.log1p(df[col]+1)\n",
    "            print('Normalized with natural log.')\n",
    "        elif normalize == 'log2':\n",
    "            for col in df.columns:\n",
    "                df[col] = np.log1p(df[col]+1)\n",
    "            print('Normalized with log2.')\n",
    "                \n",
    "    if upsampling:\n",
    "        df =df.dropna().reset_index(drop=True)\n",
    "        sm = SMOTE(random_state=32)\n",
    "        X, label = sm.fit_resample(df.iloc[:,:-1],label)\n",
    "        df = pd.DataFrame(X, columns=df.columns)\n",
    "        print('Upsampled.')\n",
    "    \n",
    "    if hybrid:\n",
    "        temp = df.copy()\n",
    "        for col in df.columns:\n",
    "            df[col] = np.log10(df[col]+1)\n",
    "        scaler = MinMaxScaler(feature_range=(0,fr))\n",
    "        temp.iloc[:,:] = scaler.fit_transform(temp.iloc[:,:])\n",
    "#         if mode == 'train':\n",
    "#             df = pd.concat([df.iloc[:,:], temp.iloc[:,:], label], axis = 1)\n",
    "#         else:\n",
    "        df = pd.concat([df.iloc[:,:], temp.iloc[:,:]], axis = 1)\n",
    "        print('Created with hybrid')\n",
    "    \n",
    "    if (mode == 'train'):\n",
    "        print('Append Label.')\n",
    "        df['label'] = label\n",
    "    print(df.columns)\n",
    "    df.columns = [str(i) for i in range(df.shape[1])]\n",
    "    \n",
    "    print('*'*50)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(df, method=None):\n",
    "    \n",
    "    if method =='automl':\n",
    "        model = TabularPredictor(label=str(df.shape[1]-1), problem_type='binary', eval_metric='accuracy')\n",
    "        model.fit(\n",
    "            df, \n",
    "            presets='best_quality', \n",
    "            hyperparameters = {\n",
    "                'NN_TORCH': {}, \n",
    "                'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, \n",
    "                        {'ag_args_fit': {'num_gpus': 1}}, \n",
    "                        'GBMLarge'],\n",
    "                'CAT': {}, \n",
    "                'XGB': [\n",
    "                        {'booster':'gbtree', 'tree_method':'exact', 'eta':0.2, 'ag_args': {'name_suffix': '_GBT_EXACT_0_2'}},\n",
    "                        {'booster':'gblinear', 'tree_method':'exact', 'eta':0.2, 'ag_args': {'name_suffix': '_GBL_EXACT_0_2'}}\n",
    "#                     ,{'booster':'dart', 'tree_method':'exact', 'eta':0.2, 'ag_args': {'name_suffix':  '_DART_EXACT_0_2'}}\n",
    "                ], \n",
    "                'FASTAI': [{'layers':[200,100]},\n",
    "                           {'layers':[128,64]},\n",
    "                           {}],  \n",
    "                'RF': [{'criterion': 'gini', 'n_estimators':200, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, \n",
    "                       {'criterion': 'entropy', 'n_estimators':200, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}},\n",
    "                       {'criterion': 'squared_error', 'n_estimators':200, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}},],\n",
    "                'XT': [{'criterion': 'gini', 'n_estimators':200, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}, },\n",
    "                       {'criterion': 'entropy', 'n_estimators':200, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}, }, \n",
    "                       {'criterion': 'squared_error', 'n_estimators':200, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}},],\n",
    "        #         'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}},\n",
    "        #                 {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}},],\n",
    "                'LR': [{'penalty': 'L1', 'ag_args': {'name_suffix': '_L1'}},\n",
    "                       {'penalty': 'L2', 'ag_args': {'name_suffix': '_L2'}}]\n",
    "        #         'NN_MXNET': {}\n",
    "        #         'TRANSF':{}\n",
    "            },\n",
    "            auto_stack=True,\n",
    "            num_bag_folds=5,\n",
    "            num_stack_levels=4,\n",
    "            verbosity=2,\n",
    "            ag_args_fit={'num_gpus': 1}\n",
    "        )\n",
    "\n",
    "        print(model.fit_summary())\n",
    "        print(model.evaluate(df))\n",
    "        print('Leader Board\\n',model.leaderboard(df, silent=True))\n",
    "\n",
    "    elif method == 'SVC':\n",
    "        param_grid = {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "            'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'cache_size': [2048],\n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'decision_function_shape':['ovo', 'ovr']\n",
    "        }\n",
    "        model = GridSearchCV(estimator=SVC(), param_grid=param_grid, scoring= ['accuracy', 'f1', 'roc_auc'], \n",
    "                            n_jobs=-1, cv=5, verbose=2, return_train_score=True, refit='accuracy' )\n",
    "        model.fit(df.iloc[:,:-1].to_numpy(), df.iloc[:,-1:].to_numpy().reshape(-1,))\n",
    "        best_estimator = model.best_estimator_\n",
    "        print('Best estimator:', best_estimator)\n",
    "\n",
    "    elif method == 'linear':\n",
    "        alpha = [0.001, 0.01, 0.1, 1, 10, 0.005, 0.05, 0.5, 5]\n",
    "        scoring=['accuracy']\n",
    "        solver=['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "        class_weight= [None, 'balanced']\n",
    "        verbose = [2]\n",
    "        best_acc = 0\n",
    "        best_params = []\n",
    "\n",
    "        for i in alpha:\n",
    "            for j in solver:\n",
    "                for k in class_weight:\n",
    "                    if j in ['lbfgs','auto']:\n",
    "                        model=RidgeClassifier(alpha=i, solver = j, class_weight = k  ,positive=True)\n",
    "                    else:\n",
    "                        model=RidgeClassifier(alpha=i, solver = j, class_weight = k )\n",
    "                    model.fit(df.iloc[:,:-1].to_numpy(), df.iloc[:,-1:].to_numpy().reshape(-1,))\n",
    "                    \n",
    "                    pred = model.predict(df.iloc[:,:-1].to_numpy())\n",
    "                    acc = accuracy_score(train_data_fin_grid.iloc[:,-1:].to_numpy().reshape(-1,), pred)\n",
    "                    print(f'Alpha {i:6} Solver {j:13} Class weight {str(k):10} Normalize {l:5} ACC {acc}')\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_params = [i,j,k,l]\n",
    "        print('Best accuracy:', best_acc)\n",
    "        print('Best parameter:', best_params)\n",
    "              \n",
    "    elif method == 'boosting':\n",
    "        model = RandomForestClassifier(n_estimators=200).fit(model.iloc[:,:-1], model.iloc[:,-1:])\n",
    "    elif method == 'bagging':\n",
    "        param_grid = {\n",
    "            'base_estimator': [RidgeClassifier(), SVC() ,RandomForestClassifier(),LogisticRegression(),ElasticNet() ],\n",
    "            'n_estimators' : [50,100,150,200,250,300,400,500,600,700],\n",
    "            'learning_rate': [0.0001,0.0001, 0.001, 0.01, 0.1, 1],\n",
    "            'algorithm': ['SAMME', 'SAMME.R']\n",
    "        }\n",
    "        model = GridSearchCV(estimator=AdaBoostClassifier(), param_grid=param_grid, scoring= ['accuracy', 'f1', 'roc_auc'], \n",
    "                            n_jobs=-1, cv=5, verbose=2, return_train_score=True, refit='accuracy' )\n",
    "        model.fit(df.iloc[:,:-1].to_numpy(), df.iloc[:,-1:].to_numpy().reshape(-1,))\n",
    "        best_estimator = model.best_estimator_\n",
    "        print('Best estimator:', best_estimator)\n",
    "    \n",
    "    pred = model.predict(df.iloc[:,:-1])\n",
    "    acc = accuracy_score(df.iloc[:,-1:].to_numpy().reshape(-1,), pred)\n",
    "    print('Accuracy on training dataset:',acc)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_and_save(model, test_df):\n",
    "    y_pred = model.predict(test_df)\n",
    "    y_pred = y_pred.astype('int64')\n",
    "    submission = pd.read_csv(f\"sample_submission.csv\")\n",
    "    submission['label'] = y_pred\n",
    "    submission.to_csv('./submission.csv', index=False)\n",
    "    print('Prediction Saved')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220515_144033\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220515_144033\\\"\n",
      "AutoGluon Version:  0.4.1b20220507\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    86\n",
      "Train Data Columns: 6\n",
      "Label Column: 6\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    86644.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 5 stack levels (L1 to L5) ...\n",
      "Fitting 16 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Mode: train\n",
      "Dropped NA value\n",
      "saved label 86\n",
      "Dropped cols ['id', 'Age', 'Sex 0M1F', 'CD8+T (cells/ul)', 'CD4+T (cells/ul)', 'Mono CD64+MFI (cells/ul)']\n",
      "Normalized with log10.\n",
      "Append Label.\n",
      "Index(['MO HLADR+ MFI (cells/ul)', 'Neu CD64+MFI (cells/ul)',\n",
      "       'CD3+T (cells/ul)', 'NK (cells/ul)', 'CD19+ (cells/ul)',\n",
      "       'CD45+ (cells/ul)', 'label'],\n",
      "      dtype='object')\n",
      "**************************************************\n",
      "**************************************************\n",
      "Mode: test\n",
      "Dropped cols ['id', 'Age', 'Sex 0M1F', 'CD8+T (cells/ul)', 'CD4+T (cells/ul)', 'Mono CD64+MFI (cells/ul)']\n",
      "Normalized with log10.\n",
      "Index(['MO HLADR+ MFI (cells/ul)', 'Neu CD64+MFI (cells/ul)',\n",
      "       'CD3+T (cells/ul)', 'NK (cells/ul)', 'CD19+ (cells/ul)',\n",
      "       'CD45+ (cells/ul)'],\n",
      "      dtype='object')\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9302\t = Validation score   (accuracy)\n",
      "\t13.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9302\t = Validation score   (accuracy)\n",
      "\t13.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.8953\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.8953\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = read_data('train.csv')\n",
    "df_test = read_data('test.csv')\n",
    "set_a = ['id', 'Age', 'Sex 0M1F', 'CD8+T (cells/ul)','CD4+T (cells/ul)', 'Mono CD64+MFI (cells/ul)' ]\n",
    "set_b = ['id', 'Age', 'Sex 0M1F', 'CD8+T (cells/ul)','CD4+T (cells/ul)']\n",
    "set_c = ['id', 'Age', 'Sex 0M1F', 'CD8+T (cells/ul)','CD4+T (cells/ul)', 'Mono CD64+MFI (cells/ul)', 'MO HLADR+ MFI (cells/ul)']\n",
    "\n",
    "selected = set_a\n",
    "\n",
    "# data_exploration(df)\n",
    "\n",
    "df = data_processing(df, mode='train', hybrid=False , \n",
    "                     drop_cols=selected,\n",
    "                     dropna=True, drop_outlier=0, normalize='log', fr=3, upsampling=False, aggregate = False)\n",
    "\n",
    "df_test = data_processing(df_test, mode='test', hybrid=False , \n",
    "                     drop_cols=selected,  \n",
    "                          dropna=False, drop_outlier=0, normalize='log', fr=3, upsampling=False, aggregate = False)\n",
    "# data_exploration(df)\n",
    "\n",
    "# df['5'] = df['1'] + df['2'] + df['3']\n",
    "# df = df.drop(['1','2', '3'], axis =1)\n",
    "# df.columns = [str(i) for i in range(df.shape[1])]\n",
    "\n",
    "\n",
    "# df_test['5'] = df_test['1'] + df_test['2'] + df_test['3']\n",
    "# df_test = df_test.drop(['1','2', '3'], axis =1)\n",
    "# df_test.columns = [str(i) for i in range(df_test.shape[1])]\n",
    "\n",
    "# df.corr()\n",
    "model_v3 = model_prediction(df, method='automl')\n",
    "\n",
    "predict_test_and_save(model_v3, df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3-MSBD5001_INDI] *",
   "language": "python",
   "name": "conda-env-Anaconda3-MSBD5001_INDI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
